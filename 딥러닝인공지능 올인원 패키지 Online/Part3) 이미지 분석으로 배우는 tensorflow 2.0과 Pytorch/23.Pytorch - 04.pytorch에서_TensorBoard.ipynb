{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "lr = 0.001\n",
    "momentum = 0.5\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "epochs = 1000\n",
    "no_cuda = False\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths = glob('../dataset/mnist_png/training/*/*.png')[:1000]\n",
    "test_paths = glob('../dataset/mnist_png/testing/*/*.png')[:1000]\n",
    "\n",
    "len(train_paths), len(test_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_paths, transform=None):\n",
    "\n",
    "        self.data_paths = data_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.data_paths[idx]\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        label = int(path.split('\\\\')[-2])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(train_paths, \n",
    "            transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(), \n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize(\n",
    "                    mean=[0.406], \n",
    "                    std=[0.225])])\n",
    "           ),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(test_paths,\n",
    "           transforms.Compose([\n",
    "               transforms.ToTensor(), \n",
    "               transforms.Normalize(\n",
    "                   mean=[0.406], \n",
    "                   std=[0.225])])\n",
    "           ),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1000 (0%)]\tLoss: 0.001403\n",
      "\n",
      "Test set: Average loss: 0.1381, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/1000 (0%)]\tLoss: 0.001536\n",
      "\n",
      "Test set: Average loss: 0.1387, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/1000 (0%)]\tLoss: 0.001246\n",
      "\n",
      "Test set: Average loss: 0.1393, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/1000 (0%)]\tLoss: 0.001135\n",
      "\n",
      "Test set: Average loss: 0.1399, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/1000 (0%)]\tLoss: 0.001270\n",
      "\n",
      "Test set: Average loss: 0.1405, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/1000 (0%)]\tLoss: 0.001109\n",
      "\n",
      "Test set: Average loss: 0.1410, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/1000 (0%)]\tLoss: 0.001071\n",
      "\n",
      "Test set: Average loss: 0.1416, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/1000 (0%)]\tLoss: 0.001130\n",
      "\n",
      "Test set: Average loss: 0.1421, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/1000 (0%)]\tLoss: 0.001019\n",
      "\n",
      "Test set: Average loss: 0.1426, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/1000 (0%)]\tLoss: 0.001019\n",
      "\n",
      "Test set: Average loss: 0.1431, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/1000 (0%)]\tLoss: 0.001130\n",
      "\n",
      "Test set: Average loss: 0.1436, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 12 [0/1000 (0%)]\tLoss: 0.000918\n",
      "\n",
      "Test set: Average loss: 0.1441, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/1000 (0%)]\tLoss: 0.001013\n",
      "\n",
      "Test set: Average loss: 0.1446, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/1000 (0%)]\tLoss: 0.001002\n",
      "\n",
      "Test set: Average loss: 0.1451, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/1000 (0%)]\tLoss: 0.000829\n",
      "\n",
      "Test set: Average loss: 0.1455, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/1000 (0%)]\tLoss: 0.000787\n",
      "\n",
      "Test set: Average loss: 0.1459, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/1000 (0%)]\tLoss: 0.000739\n",
      "\n",
      "Test set: Average loss: 0.1464, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/1000 (0%)]\tLoss: 0.000766\n",
      "\n",
      "Test set: Average loss: 0.1468, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/1000 (0%)]\tLoss: 0.000745\n",
      "\n",
      "Test set: Average loss: 0.1472, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/1000 (0%)]\tLoss: 0.000739\n",
      "\n",
      "Test set: Average loss: 0.1476, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/1000 (0%)]\tLoss: 0.000689\n",
      "\n",
      "Test set: Average loss: 0.1480, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/1000 (0%)]\tLoss: 0.000698\n",
      "\n",
      "Test set: Average loss: 0.1484, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/1000 (0%)]\tLoss: 0.000734\n",
      "\n",
      "Test set: Average loss: 0.1488, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/1000 (0%)]\tLoss: 0.000595\n",
      "\n",
      "Test set: Average loss: 0.1492, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/1000 (0%)]\tLoss: 0.000707\n",
      "\n",
      "Test set: Average loss: 0.1495, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/1000 (0%)]\tLoss: 0.000599\n",
      "\n",
      "Test set: Average loss: 0.1499, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/1000 (0%)]\tLoss: 0.000605\n",
      "\n",
      "Test set: Average loss: 0.1503, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/1000 (0%)]\tLoss: 0.000653\n",
      "\n",
      "Test set: Average loss: 0.1506, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/1000 (0%)]\tLoss: 0.000629\n",
      "\n",
      "Test set: Average loss: 0.1509, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/1000 (0%)]\tLoss: 0.000614\n",
      "\n",
      "Test set: Average loss: 0.1513, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/1000 (0%)]\tLoss: 0.000534\n",
      "\n",
      "Test set: Average loss: 0.1516, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 32 [0/1000 (0%)]\tLoss: 0.000601\n",
      "\n",
      "Test set: Average loss: 0.1519, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/1000 (0%)]\tLoss: 0.000588\n",
      "\n",
      "Test set: Average loss: 0.1523, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/1000 (0%)]\tLoss: 0.000556\n",
      "\n",
      "Test set: Average loss: 0.1526, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/1000 (0%)]\tLoss: 0.000553\n",
      "\n",
      "Test set: Average loss: 0.1529, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/1000 (0%)]\tLoss: 0.000464\n",
      "\n",
      "Test set: Average loss: 0.1532, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 37 [0/1000 (0%)]\tLoss: 0.000537\n",
      "\n",
      "Test set: Average loss: 0.1535, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 38 [0/1000 (0%)]\tLoss: 0.000500\n",
      "\n",
      "Test set: Average loss: 0.1538, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 39 [0/1000 (0%)]\tLoss: 0.000515\n",
      "\n",
      "Test set: Average loss: 0.1541, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/1000 (0%)]\tLoss: 0.000503\n",
      "\n",
      "Test set: Average loss: 0.1544, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 41 [0/1000 (0%)]\tLoss: 0.000465\n",
      "\n",
      "Test set: Average loss: 0.1547, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 42 [0/1000 (0%)]\tLoss: 0.000495\n",
      "\n",
      "Test set: Average loss: 0.1550, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 43 [0/1000 (0%)]\tLoss: 0.000455\n",
      "\n",
      "Test set: Average loss: 0.1552, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 44 [0/1000 (0%)]\tLoss: 0.000407\n",
      "\n",
      "Test set: Average loss: 0.1555, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 45 [0/1000 (0%)]\tLoss: 0.000501\n",
      "\n",
      "Test set: Average loss: 0.1558, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 46 [0/1000 (0%)]\tLoss: 0.000414\n",
      "\n",
      "Test set: Average loss: 0.1560, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 47 [0/1000 (0%)]\tLoss: 0.000413\n",
      "\n",
      "Test set: Average loss: 0.1563, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 48 [0/1000 (0%)]\tLoss: 0.000470\n",
      "\n",
      "Test set: Average loss: 0.1566, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 49 [0/1000 (0%)]\tLoss: 0.000444\n",
      "\n",
      "Test set: Average loss: 0.1568, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 50 [0/1000 (0%)]\tLoss: 0.000383\n",
      "\n",
      "Test set: Average loss: 0.1571, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 51 [0/1000 (0%)]\tLoss: 0.000377\n",
      "\n",
      "Test set: Average loss: 0.1573, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 52 [0/1000 (0%)]\tLoss: 0.000474\n",
      "\n",
      "Test set: Average loss: 0.1576, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 53 [0/1000 (0%)]\tLoss: 0.000400\n",
      "\n",
      "Test set: Average loss: 0.1578, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 54 [0/1000 (0%)]\tLoss: 0.000382\n",
      "\n",
      "Test set: Average loss: 0.1581, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 55 [0/1000 (0%)]\tLoss: 0.000389\n",
      "\n",
      "Test set: Average loss: 0.1583, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 56 [0/1000 (0%)]\tLoss: 0.000406\n",
      "\n",
      "Test set: Average loss: 0.1585, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 57 [0/1000 (0%)]\tLoss: 0.000396\n",
      "\n",
      "Test set: Average loss: 0.1588, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 58 [0/1000 (0%)]\tLoss: 0.000382\n",
      "\n",
      "Test set: Average loss: 0.1590, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 59 [0/1000 (0%)]\tLoss: 0.000362\n",
      "\n",
      "Test set: Average loss: 0.1592, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 60 [0/1000 (0%)]\tLoss: 0.000406\n",
      "\n",
      "Test set: Average loss: 0.1594, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 61 [0/1000 (0%)]\tLoss: 0.000335\n",
      "\n",
      "Test set: Average loss: 0.1597, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 62 [0/1000 (0%)]\tLoss: 0.000331\n",
      "\n",
      "Test set: Average loss: 0.1599, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 63 [0/1000 (0%)]\tLoss: 0.000310\n",
      "\n",
      "Test set: Average loss: 0.1601, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 64 [0/1000 (0%)]\tLoss: 0.000331\n",
      "\n",
      "Test set: Average loss: 0.1603, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 65 [0/1000 (0%)]\tLoss: 0.000374\n",
      "\n",
      "Test set: Average loss: 0.1605, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 66 [0/1000 (0%)]\tLoss: 0.000298\n",
      "\n",
      "Test set: Average loss: 0.1607, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 67 [0/1000 (0%)]\tLoss: 0.000300\n",
      "\n",
      "Test set: Average loss: 0.1610, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 68 [0/1000 (0%)]\tLoss: 0.000282\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a3825e9f5da2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-3a39cbbb3770>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    # Train Mode\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)  # https://pytorch.org/docs/stable/nn.html#nll-loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "    # Test mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "    \n",
    "    if epoch == 0:\n",
    "        grid = torchvision.utils.make_grid(data)\n",
    "        writer.add_image('images', grid, epoch)\n",
    "        writer.add_graph(model, data)\n",
    "        \n",
    "    writer.add_scalar('Loss/train/', loss, epoch)\n",
    "    writer.add_scalar('Loss/test/', test_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/test', accuracy, epoch)\n",
    "    \n",
    "    #tensorboard --logdir=./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
